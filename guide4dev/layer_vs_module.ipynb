{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aac96dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# khai báo mạng NN bằng nn.Squential\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced6b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# với cách khai báo này, ta không cần xây dựng lớp kế thừa nn.Module\n",
    "# mà chỉ cần sử dụng lớp nn.Sequential để xếp chồng các lớp với nhau, thư viện sẽ tự tính toán bước forwward và backward\n",
    "\n",
    "net = nn.Sequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e4c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# khi muốn mô hình phức tạp hơn, tạo 1 class kế thừa từ nn.Module\n",
    "# và cần định nghĩa hai hàm chính: __init__: khai báo các layer sẽ dùng\n",
    "# và forward: cách dữ liệu đi qua các layer đó như thế nào\n",
    "# ưu điểm của cách này là linh hoạt, cài đạt được các mô hình phức tạp hơn(CNN, RNN...)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256) # Khai báo\n",
    "        self.out = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Định nghĩa luồng xử lý\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = MLP()\n",
    "net(X).shape    \n",
    "#tuy nhiên ta vẫn có thể dùng nn.Sequential bên trong lớp kế thừa nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4d02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#module Squential hoạt động như sau:\n",
    "# chúng ta thêm từng mô đun bằng phương thức add_module\n",
    "# các mô đun được lưu trữ theo thứ tự chúng được thêm vào và có thể được truy cập thông qua phương thức children\n",
    "# trong phương thức forward, ta lặp qua từng mô đun con và áp dụng chúng tuần tự cho đầu vào X\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for module in self.children():\n",
    "            X = module(X)\n",
    "        return X\n",
    "    \n",
    "net = MySequential(nn.LazyLinear(256), nn.ReLU(), nn.LazyLinear(10))\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b2a4589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1507, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lớp squential giúp việc xây dựng mô hình trở nên dễ dàng, cho phép chúng ta lắp ráp các kiến trúc mới mà không cần tự định nghĩa lớp riêng\n",
    "#tuy nhiên có cá kiến trúc phức tạp hơn, cần thực hiện các phép toán tùy ý chứ không dựa vào các lớp nn đã được định nghĩa trước\n",
    "\n",
    "# Chúng ta có thể kết hợp nhiều cách khác nhau để lắp ráp các mô-đun lại với nhau.\n",
    "# Trong ví dụ sau, chúng ta sẽ lồng ghép các mô-đun theo một số cách sáng tạo.\n",
    "\n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Random weight parameters that will not compute gradients and\n",
    "        # therefore keep constant during training\n",
    "        self.rand_weight = torch.rand((20, 20))\n",
    "        self.linear = nn.LazyLinear(20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(X @ self.rand_weight + 1)\n",
    "        # Reuse the fully connected layer. This is equivalent to sharing\n",
    "        # parameters with two fully connected layers\n",
    "        X = self.linear(X)\n",
    "        # Control flow\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.LazyLinear(64), nn.ReLU(),\n",
    "                                 nn.LazyLinear(32), nn.ReLU())\n",
    "        self.linear = nn.LazyLinear(16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.LazyLinear(20), FixedHiddenMLP())\n",
    "chimera(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5554bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2151, -0.5308, -0.2259,  0.5902,  0.2067,  0.9651, -0.4999, -1.2603,\n",
      "          0.8167, -0.4721,  0.2084, -0.6674, -0.2071,  0.3930, -0.0323],\n",
      "        [-0.3996, -0.8507, -0.4302, -0.9287,  0.2898,  0.1542,  0.0946,  0.5835,\n",
      "          0.1162,  0.3871,  0.0266, -0.3982,  0.5140, -0.2887,  0.5076]],\n",
      "       grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net1.weight',\n",
       "              tensor([[-1.9397e-02,  4.7253e-04,  7.7692e-02, -9.2073e-02,  1.3591e-01,\n",
       "                        4.3496e-02,  1.6036e-01,  1.9428e-01,  1.9738e-01, -3.7790e-02,\n",
       "                        5.6512e-03, -3.7642e-02,  1.7422e-01,  1.9512e-01,  1.2719e-01,\n",
       "                       -1.0816e-01,  1.3560e-01,  5.3789e-04,  7.3464e-02,  9.4677e-02],\n",
       "                      [-1.1808e-01, -2.1036e-02,  7.3819e-02,  2.1821e-01,  1.9521e-02,\n",
       "                       -9.5672e-02,  5.9470e-02,  5.7355e-03,  6.4888e-02, -1.3629e-01,\n",
       "                        1.8840e-01, -1.0153e-01, -5.6176e-02, -6.8100e-03,  1.4118e-01,\n",
       "                        1.9593e-01,  2.4483e-02,  7.2193e-02,  1.7772e-01,  1.8065e-02],\n",
       "                      [-1.7216e-02, -6.7794e-02,  1.1102e-01,  1.7209e-01,  1.6185e-01,\n",
       "                        1.5640e-01, -2.9872e-02,  5.2600e-02, -1.0563e-01, -1.1272e-01,\n",
       "                       -6.8660e-02, -2.1458e-01,  7.6510e-02,  1.6430e-01, -5.1042e-02,\n",
       "                       -1.8790e-01, -5.3651e-02,  1.6735e-01,  1.2024e-01, -9.6150e-02],\n",
       "                      [-7.9680e-02, -5.3412e-03,  1.6845e-01,  1.8463e-01,  1.1098e-01,\n",
       "                        8.6490e-02,  2.2098e-01,  4.8178e-02, -7.8919e-02, -7.4617e-02,\n",
       "                        1.9692e-01, -9.1544e-02,  1.2233e-01, -1.3215e-01,  1.8147e-01,\n",
       "                       -1.9251e-01, -1.5017e-01,  1.3660e-01, -1.1099e-01, -2.1144e-01],\n",
       "                      [ 1.4187e-01, -6.0843e-02, -4.1418e-02, -1.0666e-02,  1.0021e-01,\n",
       "                       -3.1540e-02, -1.9615e-02, -6.8236e-02,  1.6912e-01, -2.1835e-01,\n",
       "                       -1.2457e-01, -6.1551e-02,  1.3404e-02,  1.3666e-01,  1.9122e-01,\n",
       "                        1.5751e-01,  1.5162e-01, -3.1340e-02,  1.1190e-01,  2.0991e-01],\n",
       "                      [-6.4126e-04, -1.5033e-01, -1.5739e-01,  8.2132e-02,  1.3257e-01,\n",
       "                        2.0066e-01, -4.1098e-02,  8.1961e-03, -2.0444e-01,  1.6662e-01,\n",
       "                       -1.8420e-01, -2.1569e-01,  5.6588e-02,  1.4152e-01,  1.2352e-01,\n",
       "                       -2.6503e-02,  2.0791e-01,  5.3102e-02, -1.4187e-01, -1.6132e-01],\n",
       "                      [-7.9689e-02, -2.1891e-01,  1.4816e-01, -1.3291e-01,  8.0078e-02,\n",
       "                       -5.2837e-02,  1.8643e-01,  1.6352e-01,  1.4765e-01,  2.0283e-01,\n",
       "                        1.2202e-01,  6.3619e-02,  1.3579e-02,  9.4103e-02,  4.5495e-02,\n",
       "                       -1.5888e-01, -1.4346e-01, -1.4434e-01, -2.0322e-01,  1.9554e-01],\n",
       "                      [-7.4574e-02, -2.2244e-01,  1.9552e-01, -2.0553e-01,  3.1173e-02,\n",
       "                       -1.9207e-02,  7.0170e-02,  1.4448e-01,  3.1731e-02, -1.1951e-01,\n",
       "                       -9.8466e-02,  1.2978e-01, -1.4905e-01,  1.9193e-01, -1.2809e-01,\n",
       "                        2.0915e-01, -6.3450e-02, -1.4800e-02, -1.6391e-01,  1.2345e-01],\n",
       "                      [ 2.2325e-01, -1.5691e-01, -1.7669e-01, -3.8150e-02, -1.3095e-01,\n",
       "                        1.4623e-04, -7.7037e-02, -1.0490e-01,  7.5846e-02, -1.6164e-01,\n",
       "                        2.1698e-02,  1.9087e-01, -9.0760e-02,  4.9383e-02,  1.6785e-01,\n",
       "                        2.1875e-01,  1.2035e-01, -1.7900e-01,  7.2419e-02,  1.3401e-03],\n",
       "                      [ 3.9885e-02, -1.1500e-01, -1.5786e-01,  1.9901e-01, -3.6953e-02,\n",
       "                       -1.1509e-01, -1.0272e-01, -2.1940e-02,  8.3616e-02, -1.3296e-01,\n",
       "                        8.0038e-02, -1.3225e-01, -1.4364e-01, -1.1189e-02,  6.8866e-03,\n",
       "                        1.1950e-02, -7.7763e-02,  1.1759e-01, -1.8753e-01,  5.7227e-02]])),\n",
       "             ('net1.bias',\n",
       "              tensor([-0.1947, -0.2152, -0.1738, -0.1443,  0.0906,  0.1822, -0.1948,  0.0348,\n",
       "                       0.0266, -0.0194])),\n",
       "             ('net2.weight',\n",
       "              tensor([[-0.1012, -0.0116,  0.1598, -0.2234,  0.1708, -0.0019,  0.0782,  0.1836,\n",
       "                       -0.0522,  0.1258,  0.0755,  0.1039,  0.0576,  0.1721, -0.0604,  0.1523,\n",
       "                        0.2230, -0.1932,  0.0624, -0.0012],\n",
       "                      [ 0.0802,  0.1221,  0.0543, -0.1364, -0.1900,  0.1217, -0.0275,  0.0328,\n",
       "                       -0.0149, -0.0611,  0.1731,  0.1767,  0.1341,  0.2193, -0.0765, -0.0949,\n",
       "                       -0.0384,  0.1897, -0.0621, -0.0557],\n",
       "                      [ 0.0799, -0.0220,  0.1373,  0.0228,  0.0289,  0.2071, -0.1355, -0.0277,\n",
       "                       -0.1300, -0.0373, -0.0866, -0.2053,  0.1012,  0.1613, -0.1778,  0.0391,\n",
       "                        0.1869,  0.0117, -0.0617,  0.0184],\n",
       "                      [-0.0413, -0.1222,  0.1167,  0.1418,  0.0605,  0.0190, -0.1689,  0.1600,\n",
       "                       -0.0440,  0.0020,  0.0042, -0.0327,  0.2170,  0.1048,  0.0171, -0.1276,\n",
       "                        0.0753,  0.1309, -0.1379, -0.0803],\n",
       "                      [ 0.0736,  0.0560, -0.1063,  0.0602, -0.0421,  0.1505,  0.1412,  0.0622,\n",
       "                        0.2173,  0.2151, -0.1024, -0.0232, -0.1244, -0.1260,  0.0540, -0.1939,\n",
       "                        0.1747, -0.0041, -0.0448,  0.1587]])),\n",
       "             ('net2.bias',\n",
       "              tensor([-0.0561, -0.0715,  0.1977,  0.1711, -0.0233]))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mô đun song song\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ParallelModule(nn.Module):\n",
    "    def __init__(self, net1, net2):\n",
    "        super().__init__()\n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Tính toán song song\n",
    "        out1 = self.net1(x)\n",
    "        out2 = self.net2(x)\n",
    "        \n",
    "        # Nối kết quả lại với nhau.\n",
    "        # dim=1 thường là chiều features (dim=0 là batch size)\n",
    "        return torch.cat((out1, out2), dim=1)\n",
    "\n",
    "# --- Kiểm thử ---\n",
    "# Giả sử net1 ra 10 đặc trưng, net2 ra 5 đặc trưng\n",
    "net1 = nn.Linear(20, 10)\n",
    "net2 = nn.Linear(20, 5)\n",
    "\n",
    "model = ParallelModule(net1, net2)\n",
    "x = torch.randn(2, 20) # Batch size = 2, Input features = 20\n",
    "\n",
    "output = model(x)\n",
    "print(output) \n",
    "# Kết quả mong đợi: torch.Size([2, 15]) (vì 10 + 5 = 15)\n",
    "model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
